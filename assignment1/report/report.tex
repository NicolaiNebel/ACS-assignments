\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[head=26pt, a4paper, margin=1.2in, top=1.4in, bottom=1.75in]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[hidelinks, colorlinks, urlcolor=blue, linkcolor=black,citecolor=magenta]
{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
\usepackage{mathtools}

% ---------------- Page and margin/header/footer Setup -----------------
\pagestyle{fancy}
%\fancyhf{} % Clears header and footer
\fancyhead{}
\fancyfoot{}
\lhead{ACS --- Assignment 1}
\rhead{DIKU}
\lfoot{Page \thepage\ of \pageref{LastPage}}
\rfoot{Yiran Zhang\\Nicolai Jørgensen}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
% ----------------------------------------------------------------------

\newtheorem{mythm}{Theorem}
\newtheorem{mydef}{Definition}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\title          {Assignment 1}
\author         {Yiran Zhang and Nicolai Jørgensen}

\begin{document}

\maketitle
\newpage

\section{Question 1}

In order to organise memory with physical storage on several machines, we are
going to split the top-level memory into pages. Additionally, we will maintain a
map between the top-level pages and a tuple of machine identifier and local
address. The mapping can be implemented to run in $O(log n)$ time, with $n$ being the
number of allocated pages, which can be kept small by choosing suitably large
page sizes.

In addition, we will for each machine maintain a list of its pages and the
number of pages it has allocated. The length of the list can be used to load
balance the system, by evenly splitting the memory between available machines.
When a machine leaves the system, all of its pages can be copied to prevent data
loss.

In the pseudocode below, we assume calls to address directly into the big
contiguous memory space. That is, there is no virtual memory addressing going
on.
\begin{Verbatim}
READ(addr):
  (PageNo, Offset) = (addr / page_size, addr % page_size)
  if (exists(page_map, PageNo)):
    (Machine, MachineAddr) = lookup(page_map, PageNo)
    v = RemoteREAD(Machine, MachineAddr + Offset)
    if      v == segfault: return segfault
    else if v == timeout:  try again a set number of times, if still no success, return timeout
    else:                  return v
  else:
    return segfault

WRITE(addr, value):
  (PageNo, Offset) <- (addr / page_size, addr % page_size)
  if (exists(page_map, PageNo)):
    (Machine, MachineAddr) = lookup(page_map, PageNo)
    return RemoteWRITE(Machine, MachineAddr + Offset, value)
  else:
    if system has space for a new page:
      (Machine, MachineAddr) = allocate_new_page(PageNo),
      add(page_map, PageNo, (Machine, MachineAddr))
      RemoteWRITE(Machine, MachineAddr + Offset, value)
    else:
      return segfault

RemoteREAD(Machine, Addr):
  Ask Machine to READ(Addr)
  Wait for response:
    On return:   return value
    On segfault: return segfault
  On timeout:  return timeout

RemoteWRITE(Machine, Addr, Value):
  Ask Machine to WRITE(Addr, Value)

allocate_new_page(PageNo):
  find machine with least pages (O(logn))
  try to allocate page:
  on fail:
    remove machine from list of available machines for allocation
    allocate_new_page(PageNo)
  on success:
    return (machine, allocated page addr)

\end{Verbatim}
The page numbers and offsets are calculated using simple integer division and
modulo. The functions \verb|lookup|, \verb|get| and \verb|add| refer to a map
structure with $O(logn)$ running times implemented with e.g a binary search
tree.\\

We believe that memory access against the unified memory space need not
necessarily be atomic. However, memory access to addresses in individual
machines still need to preserve this basic integrity. That is, we should be able
to distribute the memory access computation between machines.\\

Our name mapping strategy makes an assumption about the system setup.
We assume that we know the addresses, and thus also the quantity, of machines in
the unified memory space. Then, we use that information to dynamically spread
allocated pages over the machines.

Our system also allows for dynamic leaves and joins of machines in the memory
space. Joining is simple, we just inform the system that a new machine is
available with no pages allocated yet. Leaving is a bit more complicated, but
can be done by iterating over the pages it had allocated. Each page should be
allocated on and copied unto another machine. The leave operation should inform
the system if some data could not be copied.

\section{Question 2}




Caching is indeed an example of a fast path optimization. Fast path optimization
refers to designing system to make it fast in the common case. The concept of
"locality of reference" occurs almost naturally when designing programs.
We are specifically referring to temporal and spatial locality, which means that
if one memory address is accessed, it and its neighbours are more likely to be
accessed in the near future. Caching the entire page of an address makes lookups
to these addresses faster, thus optimizing the common case.

\end{document}
