\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[head=26pt, a4paper, margin=1.2in, top=1.4in, bottom=1.75in]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[hidelinks, colorlinks, urlcolor=blue, linkcolor=black,citecolor=magenta]
{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
\usepackage{mathtools}

% ---------------- Page and margin/header/footer Setup -----------------
\pagestyle{fancy}
%\fancyhf{} % Clears header and footer
\fancyhead{}
\fancyfoot{}
\lhead{ACS --- Assignment 1}
\rhead{DIKU}
\lfoot{Page \thepage\ of \pageref{LastPage}}
\rfoot{Yiran Zhang\\Nicolai Jørgensen}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
% ----------------------------------------------------------------------

\newtheorem{mythm}{Theorem}
\newtheorem{mydef}{Definition}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\title          {Assignment 1}
\author         {Yiran Zhang and Nicolai Jørgensen}

\begin{document}

\maketitle
\newpage

\section{Question 1}

In order to organise memory with physical storage on several machines, we are
going to split the top-level memory into pages. Additionally, we will maintain a
map between the top-level pages and a tuple of machine identifier and local
address. The mapping can be implemented to run in $O(log n)$ time, with $n$ being the
number of allocated pages, which can be kept small by choosing suitably large
page sizes.

In addition, we will for each machine maintain a list of its pages and the
number of pages it has allocated. The length of the list can be used to load
balance the system, by evenly splitting the memory between available machines.
When a machine leaves the system, all of its pages can be copied to prevent data
loss.

In the pseudocode below, we assume calls to address directly into the big
contiguous memory space. That is, there is no virtual memory addressing going
on.
\begin{Verbatim}
READ(addr):
  (PageNo, Offset) = (addr / page_size, addr % page_size)
  if (exists(page_map, PageNo)):
    (Machine, MachineAddr) = lookup(page_map, PageNo)
    v = RemoteREAD(Machine, MachineAddr + Offset)
    if      v == segfault: return segfault
    else if v == timeout:  try again a set number of times, if still no success, return timeout
    else:                  return v
  else:
    return segfault

WRITE(addr, value):
  (PageNo, Offset) <- (addr / page_size, addr % page_size)
  if (exists(page_map, PageNo)):
    (Machine, MachineAddr) = lookup(page_map, PageNo)
    return RemoteWRITE(Machine, MachineAddr + Offset, value)
  else:
    if system has space for a new page:
      (Machine, MachineAddr) = allocate_new_page(PageNo),
      add(page_map, PageNo, (Machine, MachineAddr))
      RemoteWRITE(Machine, MachineAddr + Offset, value)
    else:
      return segfault

RemoteREAD(Machine, Addr):
  Ask Machine to READ(Addr)
  Wait for response:
    On return:   return value
    On segfault: return segfault
  On timeout:  return timeout

RemoteWRITE(Machine, Addr, Value):
  Ask Machine to WRITE(Addr, Value)

allocate_new_page(PageNo):
  find machine with least pages (O(logn))
  try to allocate page:
  on fail:
    remove machine from list of available machines for allocation
    allocate_new_page(PageNo)
  on success:
    return (machine, allocated page addr)

\end{Verbatim}
The page numbers and offsets are calculated using simple integer division and
modulo. The functions \verb|lookup|, \verb|get| and \verb|add| refer to a map
structure with $O(logn)$ running times implemented with e.g a binary search
tree.\\

We believe that memory access against the unified memory space need not
necessarily be atomic. However, memory access to addresses in individual
machines still need to preserve this basic integrity. That is, we should be able
to distribute the memory access computation between machines.\\

Our name mapping strategy makes an assumption about the system setup.
We assume that we know the addresses, and thus also the quantity, of machines in
the unified memory space. Then, we use that information to dynamically spread
allocated pages over the machines.

Our system also allows for dynamic leaves and joins of machines in the memory
space. Joining is simple, we just inform the system that a new machine is
available with no pages allocated yet. Leaving is a bit more complicated, but
can be done by iterating over the pages it had allocated. Each page should be
allocated on and copied unto another machine. The leave operation should inform
the system if some data could not be copied.

\section{Question 2}




Caching is indeed an example of a fast path optimization. Fast path optimization
refers to designing system to make it fast in the common case. The concept of
"locality of reference" occurs almost naturally when designing programs.
We are specifically referring to temporal and spatial locality, which means that
if one memory address is accessed, it and its neighbours are more likely to be
accessed in the near future. Caching the entire page of an address makes lookups
to these addresses faster, thus optimizing the common case.

\section{Questions for Discussion on Architecture}
\subsection{}
when the implementation and tests succeeds it will return a result otherwise it will throw an exception

\subsection{}
For the \texttt{rateBooks} we write the following tests: test that a single valid rating is processed correctly, test that multiple ratings accumulate on a book, test test books cannot be rated if ISBN is invalid, test that books cannot be rated if a rating is invalid,test that trying to rate a book not in the score causes an error.

For the \texttt{getTopRatedBooks} we write the following tests: test that books can not be got if K is not valid, tests that a valid K can be processed correctly.

For the \texttt{getBooksIndemand} we tests that books in demand can be retrived.

\section{}
\subsection{}
In this architecture the customer sole is strongly modular. The \texttt{StockManager} and \texttt{BookStore} are complete separation.And they both have separate \texttt{HTTPProxies}. 

And all the functions corresponding to the two customer role can be called separately.


\subsection{}
The isolation is fact that the bookstore implementation and our clients have to exchange communication through a distinct layer, and we use RPCs to ask a server for the actual computation stuff

The protection is fact that the architecture has strong modularity which means it has low coupling. When one modular fails, the system can run as well

\subsection{}
The same kind of isolation is not enforced. Once the JVM breaks down,both the server and the clients will crash, as possible through the test


\section{}
\subsection{}
Yes, there is naming system, it binds the names with the address or resource. By specifying the name  we can get the resource, the service address and the provider information. Therefore users can interact with a computer through names.

\subsection{}
We use IP address to allows the clients to discover and communicate with servers

\section{}

At-most-once semantics is implemented in the architecture. Using at-most-once the RPCs will either return a calling result or throw an exception. In out implementation, when the RPC succeeds it will return the result, otherwise it throws an exception and fails.

\section{}
\subsection{}
Yes it is safe to use web proxy servers with the architecture of Figure 2

\subsection{}
Because it encrypt the communication to and from the clients. And the proxies should be deployed between the software proxies and the server where it uses the HTTP requests and responses

\section{}
\subsection{}
Yes there is scalability bottlenecks in this architecture with respect to the number of clients
\subsection{}
CPU, the RAM and the hard disk.

\section{}
\subsection{}
No. when no cache is employed in the web proxy,the clients experience failures similar if web proxies were used in the architecture.

Because the web proxies cannot store the data in cache, when the sever crash the web proxies cannot fetch the data from the remote sever and cannot return corresponding reply. Therefore the clients can experience the similar failure
\subsection{}
Yes, because web proxies store the web pages and some files in cache so when the sever crash, the web proxies can return the some datas in the cache to the clients

\subsection{}
When using at-most-once semantics, if it fails, the RPCs returns results or throws exception and the web proxies stores the results or exceptions. Therefore in the next the time, if the clients send the same request, the web proxies will directly return the results or exceptions.

\end{document}
